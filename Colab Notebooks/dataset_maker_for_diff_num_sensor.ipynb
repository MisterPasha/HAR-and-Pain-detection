{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqo8vj2z+cKDAbmYxe1Xx8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#This files' Purpose is to create datasets of various sizes by removing certain sensors for the experiment exploring impact of misalignemnt on decreased number of sensors"],"metadata":{"id":"SifRITIfSQE_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KYuidX4AQk7","executionInfo":{"status":"ok","timestamp":1740685735817,"user_tz":0,"elapsed":151718,"user":{"displayName":"Pavel Jermolajev","userId":"05342435723381561524"}},"outputId":"982825d3-2f28-4f60-8517-ef199c0eae66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","(435064, 120)\n","(153507, 120)\n","(123251, 120)\n","(435064, 81)\n","(153507, 81)\n","(123251, 81)\n"]}],"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import gc\n","\n","# -----------------------------\n","# Purpose:\n","# This script loads and preprocesses the REALDISP dataset from Google Drive.\n","# It performs the following steps:\n","# 1. Loads sensor data from 17 subjects and splits it into train, validation, and test sets.\n","# 2. Removes rows labeled as '0' (non-activity/background).\n","# 3. Converts data to float and organizes it into DataFrames.\n","# 4. Extracts features (excluding timestamps and labels).\n","# 5. Removes quaternion-related columns.\n","# -----------------------------\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Step 1: Initialize data lists for each dataset split\n","train_data = []\n","valid_data = []\n","test_data = []\n","\n","# Step 2: Read and split data by subject\n","for i in range(1, 18):  # Subjects 1 through 17\n","    file_path = f\"/content/drive/My Drive/PROJECT/REALDISP/subject{i}_ideal.log\"\n","    with open(file_path, \"r\") as file:\n","        for line in file:\n","            split_line = line.split()\n","            if split_line[-1] != \"0\":  # Skip rows with label '0' (non-activity)\n","                if i < 12:\n","                    train_data.append(split_line)  # Subjects 1–11 → Train\n","                elif i < 15:\n","                    valid_data.append(split_line)  # Subjects 12–14 → Validation\n","                else:\n","                    test_data.append(split_line)   # Subjects 15–17 → Test\n","\n","# Step 3: Convert to DataFrames and cast to float\n","df_train = pd.DataFrame(train_data).astype(float)\n","df_valid = pd.DataFrame(valid_data).astype(float)\n","df_test = pd.DataFrame(test_data).astype(float)\n","\n","print(\"Train data shape:\", df_train.shape)\n","print(\"Validation data shape:\", df_valid.shape)\n","print(\"Test data shape:\", df_test.shape)\n","\n","# Step 4: Extract features (excluding timestamp and label columns)\n","train_features = df_train.iloc[:, 2:-1]\n","train_labels = df_train.iloc[:, -1]\n","\n","valid_features = df_valid.iloc[:, 2:-1]\n","valid_labels = df_valid.iloc[:, -1]\n","\n","test_features = df_test.iloc[:, 2:-1]\n","test_labels = df_test.iloc[:, -1]\n","\n","# -----------------------------\n","# Step 5: Identify and remove quaternion columns\n","# Each 13-column block includes 4 quaternion features (to be removed)\n","columns_to_remove = []\n","start = 9        # First quaternion column (0-based index)\n","step = 13        # Distance between quaternion blocks\n","remove_count = 4 # Number of consecutive columns to remove per block\n","\n","# Collect indices to remove\n","while start <= train_features.shape[1]:\n","    columns_to_remove.extend(range(start, start + remove_count))\n","    start += step\n","\n","# Filter indices to stay within bounds\n","columns_to_remove = [col for col in columns_to_remove if col < train_features.shape[1]]\n","\n","# Remove quaternion columns from all splits\n","train_features = train_features.drop(columns=train_features.columns[columns_to_remove])\n","valid_features = valid_features.drop(columns=valid_features.columns[columns_to_remove])\n","test_features = test_features.drop(columns=test_features.columns[columns_to_remove])\n","\n","# Final shapes for verification\n","print(\"Train features shape:\", train_features.shape)\n","print(\"Validation features shape:\", valid_features.shape)\n","print(\"Test features shape:\", test_features.shape)"]},{"cell_type":"markdown","source":["#Remove Sensors"],"metadata":{"id":"lR51pRdnTR82"}},{"cell_type":"code","source":["# For each Dataset a certain set of sensors to remove\n","\n","dataset_1_sensors_to_remove = [2,7,9]  # Right and Left Upper Arms, Left Thigh\n","dataset_2_sensors_to_remove = [3,6,8]  # Right and Left Lower Arms, Right Calf\n","dataset_3_sensors_to_remove = [1,3,4,5,6,8]  # Opposite to dataset 1\n","dataset_4_sensors_to_remove = [1,2,4,5,7,9]  # Opposite to dataset 2"],"metadata":{"id":"mabolFXPNhhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_sensors(features, sensor_indices):\n","    \"\"\"\n","    Removes specified sensors from the feature array.\n","\n","    Args:\n","        features (np.ndarray): Input feature array of shape (n_samples, 81).\n","        sensor_indices (list): List of sensor indices to remove (values from 1 to 9).\n","\n","    Returns:\n","        np.ndarray: Features with specified sensors removed.\n","    \"\"\"\n","    num_sensors = 9  # Total sensors\n","    sensor_length = 9  # Features per sensor\n","\n","    # Convert sensor indices (1-based) to column index ranges\n","    cols_to_remove = []\n","    for sensor in sensor_indices:\n","        start_col = (sensor - 1) * sensor_length  # Start index\n","        end_col = start_col + sensor_length      # End index (exclusive)\n","        cols_to_remove.extend(range(start_col, end_col))\n","\n","    # Remove selected sensor columns\n","    features_reduced = np.delete(features, cols_to_remove, axis=1)\n","\n","    return features_reduced"],"metadata":{"id":"yGDP4l7wQU8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features = remove_sensors(train_features, dataset_1_sensors_to_remove)\n","valid_features = remove_sensors(valid_features, dataset_1_sensors_to_remove)\n","test_features = remove_sensors(test_features, dataset_1_sensors_to_remove)"],"metadata":{"id":"bMwVQC2UR4ZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_features.shape)\n","print(valid_features.shape)\n","print(test_features.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TtVHMnG74On8","executionInfo":{"status":"ok","timestamp":1740685778748,"user_tz":0,"elapsed":9,"user":{"displayName":"Pavel Jermolajev","userId":"05342435723381561524"}},"outputId":"03e5f8d4-1030-4efd-fc82-2828df7bd984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(435064, 54)\n","(153507, 54)\n","(123251, 54)\n"]}]},{"cell_type":"markdown","source":["#Segment and shuffle data"],"metadata":{"id":"DJuuZZV3TV6n"}},{"cell_type":"code","source":["def create_variable_size_windows(features, labels, min_size=96, max_size=128):\n","\n","    # Convert DataFrames to NumPy arrays if necessary\n","    if not isinstance(features, np.ndarray):\n","        features = features.to_numpy()\n","    if not isinstance(labels, np.ndarray):\n","        labels = labels.to_numpy()\n","\n","    n_samples, n_features = features.shape\n","    windows = []\n","    label_windows = []\n","\n","    # Step 1: Create variable-size windows\n","    i = 0\n","    while i < n_samples - min_size:\n","        # Randomly choose a window size between min_size and max_size\n","        window_size = np.random.randint(min_size, max_size + 1)\n","        #window_sizes.append(window_size)\n","\n","        # Ensure we do not exceed dataset length\n","        if i + window_size > n_samples:\n","            break\n","\n","        # Extract window and corresponding labels\n","        windows.append(features[i : i + window_size, :])  # Now works correctly\n","        label_windows.append(labels[i : i + window_size])\n","\n","        # Move to the next window\n","        i += window_size\n","\n","    # Convert lists to numpy arrays\n","    windows = np.array(windows, dtype=object)  # Use dtype=object for variable-length windows\n","    label_windows = np.array(label_windows, dtype=object)\n","\n","    # Step 2: Shuffle the windows\n","    shuffled_indices = np.random.permutation(len(windows))\n","    windows = windows[shuffled_indices]\n","    label_windows = label_windows[shuffled_indices]\n","\n","    # Step 3: Flatten the shuffled windows back into original shape\n","    shuffled_features = np.vstack(windows)  # Stack into a 2D array\n","    shuffled_labels = np.concatenate(label_windows)  # Flatten into 1D array\n","\n","    return shuffled_features.astype(np.float32), shuffled_labels.astype(np.float32)\n","\n","# Example Usage:\n","# Assuming train_features, train_labels, valid_features, valid_labels, test_features, test_labels exist\n","shuffled_train_features, shuffled_train_labels = create_variable_size_windows(train_features, train_labels, min_size=128, max_size=128)\n","shuffled_valid_features, shuffled_valid_labels = create_variable_size_windows(valid_features, valid_labels, min_size=128, max_size=128)\n","shuffled_test_features, shuffled_test_labels = create_variable_size_windows(test_features, test_labels, min_size=128, max_size=128)\n","\n","X_train_normal = shuffled_train_features\n","y_train_normal = shuffled_train_labels\n","X_valid = shuffled_valid_features\n","y_valid = shuffled_valid_labels\n","X_test = shuffled_test_features\n","y_test = shuffled_test_labels"],"metadata":{"id":"sVJejHELSSG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train_normal.shape)\n","print(y_train_normal.shape)\n","print(X_valid.shape)\n","print(y_valid.shape)\n","print(X_test.shape)\n","print(y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbgurn5F6TgK","executionInfo":{"status":"ok","timestamp":1740685810224,"user_tz":0,"elapsed":11,"user":{"displayName":"Pavel Jermolajev","userId":"05342435723381561524"}},"outputId":"465acb50-f002-46a9-d843-a65f3378d18f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(434944, 54)\n","(434944,)\n","(153472, 54)\n","(153472,)\n","(123136, 54)\n","(123136,)\n"]}]},{"cell_type":"code","source":["# Collect garbage\n","\n","del shuffled_train_features, shuffled_train_labels\n","del shuffled_valid_features, shuffled_valid_labels\n","del shuffled_test_features, shuffled_test_labels\n","del train_features, train_labels\n","del valid_features, valid_labels\n","del test_features, test_labels\n","del df_train, df_valid, df_test\n","\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJhSCgv9Sfjd","executionInfo":{"status":"ok","timestamp":1740685818906,"user_tz":0,"elapsed":18,"user":{"displayName":"Pavel Jermolajev","userId":"05342435723381561524"}},"outputId":"39820d96-689c-4c21-d423-1a71ce69ce5c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["192"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Save processed dataset with required number of sensors"],"metadata":{"id":"R0ouhcPOTeWi"}},{"cell_type":"code","source":["from scipy.io import savemat\n","\n","data_dict = {\n","    \"trainData\": X_train,\n","    \"valData\": X_valid,\n","    \"testData\": X_test,\n","    \"trainLabels\": y_train,\n","    \"valLabels\": y_valid,\n","    \"testLabels\": y_test,\n","}\n","\n","savemat(\"REALDISP_6_SENSOR_SET.mat\", data_dict, do_compression=True)"],"metadata":{"id":"j5iVq_FjSqgf"},"execution_count":null,"outputs":[]}]}